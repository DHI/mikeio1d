{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"MIKE-IO-1D-Logo-Pos-RGB-nomargin.png\" alt=\"image\" width=\"600\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, write, and analyse 1D modelling results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is MIKE IO 1D? Let's talk about what it does...\n",
    "* Reads and writes res1d and xns11 files.\n",
    "* Connects the MIKE 1D API to Python's ecosystem.\n",
    "* Integrates with libraries like Pandas, GeoPandas, and Matplotlib.\n",
    "* Enables more flexible analysis of results, as well as automation.\n",
    "* Welcomes contributions as an open-source package on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is it different from MIKE IO?\n",
    "* MIKE IO deals with dfs0, dfs1, dfs2, dfs3, dfsu and mesh files.\n",
    "* MIKE IO 1D deals with res1d and xns11 files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's new in MIKE IO 1D?\n",
    "The last DataTalk on MIKE IO 1D was in June 2022. Since then, we've added:\n",
    "* Easy network querying with autocompletion,\n",
    "* Exporting results to GeoPandas,\n",
    "* Advanced network aggregation (e.g. max discharge along chainage),\n",
    "* Pandas MultiIndex option for cleaner DataFrames,\n",
    "* Performance improvements (much faster reading),\n",
    "* Linux support,\n",
    "* Exporting to dfs0, csv, txt files (similar to ResultDataExtract.py),\n",
    "* Modify res1d files, and\n",
    "* Merge Long Term Statistics (LTS) result files.\n",
    "* ... and more still coming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What version are we at?\n",
    "\n",
    "* As of today we're at version 0.6 (after this talk).\n",
    "* Hoping for some more user adoption before a stable 1.0.\n",
    "* If you still have 0.1 installed, please update ;)\n",
    "* ... pip install -U mikeio1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered reading of the result files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to load a res1d file in a filtered way, that only specified locations are loaded into memory. Let's load nodes **1**, **2**, **3**, and reach **99l1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_network = './data/Network.res1d'\n",
    "res1d_network_filtered = Res1D(file_path_network, nodes=['1', '2', '3'], reaches=['99l1'])\n",
    "df_network_filtered = res1d_network_filtered.read_all()\n",
    "df_network_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for catchments. Let's load data for catchment **100_16_16**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_catchments = './data/Catchments.res1d'\n",
    "res1d_catchments_filtered = Res1D(file_path_catchments, catchments=['100_16_16'])\n",
    "df_catchments_filtered = res1d_catchments_filtered.read_all()\n",
    "df_catchments_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying a res1d file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show how to modify a res1d file. Such functionality is useful for modifications of a hotstart file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_network = './data/Network.res1d'\n",
    "res1d_network_mod = Res1D(file_path_network)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all node water level time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1d_network_mod.nodes.WaterLevel.add()\n",
    "df_network_mod = res1d_network_mod.read()\n",
    "print('Current maximum water level: ', df_network_mod.max().max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply the water level data by a factor of 2 and write it to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network_mod = df_network_mod.multiply(2.0)\n",
    "file_path_new = file_path_network.replace('Network.res1d', 'NetworkFactorTwo.res1d')\n",
    "res1d_network_mod.modify(df_network_mod, file_path=file_path_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data again into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1d_network_mod.nodes.WaterLevel.add()\n",
    "df_network_mod = res1d_network_mod.read()\n",
    "print('Current maximum water level: ', df_network_mod.max().max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the newly written file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New file path:', file_path_new)\n",
    "res1d_network_new = Res1D(file_path_new)\n",
    "res1d_network_new.nodes.WaterLevel.add()\n",
    "df_network_new = res1d_network_new.read()\n",
    "print('Current maximum water level:', df_network_new.max().max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting time series data to dfs0 file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to extract the res1d time series data to a dfs0 file. The idea is again to create queries, which are used to pick which time series to extract. Let's extract all node water level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1d_network.nodes.WaterLevel.add()\n",
    "file_path_dfs0 = file_path_network.replace('Network.res1d', 'NetworkNodeWaterLevel.dfs0')\n",
    "res1d_network.to_dfs0(file_path=file_path_dfs0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
